{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNu8HjHKb67STt8SXrK1sF2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio 5: Ejemplo de ejecución paralela en CUDA"
      ],
      "metadata": {
        "id": "9Vnd48XncHB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Programa: Multiplicación escalar\n",
        "\n",
        "El siguiente programa realiza una multiplicación escalar entre el vector `vector` y el valor escalar `scalar`. Además, se incluye una pequeña sección de comprobación de errores para verificar que la respuesta generada es correcta a través de la comparación entre los valores almacenados en los vectores `vector` y `original`."
      ],
      "metadata": {
        "id": "EFMERuYncUHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación"
      ],
      "metadata": {
        "id": "UgvZHBWadSwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJoeBB7Dl6Ay",
        "outputId": "e0fe1f6b-ea78-495f-d590-d9887345240c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scavec_mult.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile scavec_mult.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "void scalar_multiplication(int size, float *vector, float scalar)\n",
        "{\n",
        "  for (int i = 0; i < size; ++i)\n",
        "    vector[i] *= scalar;\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  srand(1);\n",
        "  int N = 1<<20; // 1M elements\n",
        "\n",
        "  float* vector = new float[N];\n",
        "  float* original = new float[N]; // copia para validar\n",
        "  float scalar = rand();\n",
        "\n",
        "  for (int i = 0; i < N; i++){\n",
        "    vector[i] = rand();\n",
        "    original[i] = vector[i];\n",
        "  }\n",
        "\n",
        "  scalar_multiplication(N, vector, scalar);\n",
        "\n",
        "  // --- Comprobación de errores ---\n",
        "  bool ok = true;\n",
        "  for (int i = 0; i < N; i++){\n",
        "    float expected = original[i] * scalar;\n",
        "    if (fabs(vector[i] - expected) > 1e-5f) {\n",
        "      std::cout << \"Error en índice \" << i\n",
        "                << \": obtenido = \" << vector[i]\n",
        "                << \", esperado = \" << expected << \"\\n\";\n",
        "      ok = false;\n",
        "      break;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (ok)\n",
        "    std::cout << \"Comprobación exitosa: todos los valores coinciden.\\n\";\n",
        "\n",
        "  // Free memory\n",
        "  delete [] vector;\n",
        "  delete [] original;\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilación"
      ],
      "metadata": {
        "id": "_0DDyc4xdVhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "g++ scavec_mult.cpp -o scavec_mult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGaaE2X-m5jr",
        "outputId": "3c98b934-440f-4edb-f979-847e93945c15"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados"
      ],
      "metadata": {
        "id": "YdxiewILlEot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./scavec_mult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eEzaT_3m6w5",
        "outputId": "b4d3464d-971e-445f-aed8-e57746620949"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comprobación exitosa: todos los valores coinciden.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paralelización\n",
        "\n",
        "Para paralelizar el programa a través de CUDA, se realizaron los siguientes cambios en base a la información consultada en Harris, M. (2025):\n",
        "\n",
        "- Se asigna memoria de modo que el GPU pueda acceder a ella. Esto se hace a través de un modelo de programación llamado *Unified Memory*, que provee un espacio de memoria único accesible a todos los GPUs y CPUs en el sistema. Para acceder a la *Unified Memory*, se cambiaron las declaraciones de los vectores `vector` y `original` por la función CUDA `cudaMallocManaged`, y la liberación de memoria cambió al uso de la función `cudaFree`.\n",
        "- La función principal `scalar_multiplication` se declara con la especificación `__global__` para convertirlo en un *kernel*, una función ejecutable por un GPU en CUDA (NVIDIA, 2025).\n",
        "- Para terminar la transformación de la función `scalar_multiplication` a una función *kernel*, se declaran los enteros `index` y `stride`, que representan, respectivamente, el índice del thread en ejecución y el desplazamiento hasta el comienzo de su bloque.\n",
        "- Finalmente, se hace el llamado a la nueva función *kernel* `scalar_multiplication` a través de las tres llaves angulares `<<<>>>`, en donde se incluyen las variables `blockSize` (el tamaño del bloque asignado) y `numBlocks` (el número de bloques)."
      ],
      "metadata": {
        "id": "E39Gw4fbdZ8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scavec_mult.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "__global__\n",
        "void scalar_multiplication(int size, float *vector, float scalar)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for (int i = index; i < size; i += stride)\n",
        "    vector[i] *= scalar;\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  srand(1);\n",
        "  int N = 1<<20; // 1M elements\n",
        "\n",
        "  float* vector;\n",
        "  float* original; // copia para validar\n",
        "\n",
        "  cudaMallocManaged(&vector, N*sizeof(float));\n",
        "  cudaMallocManaged(&original, N*sizeof(float));\n",
        "\n",
        "  float scalar = rand();\n",
        "\n",
        "  for (int i = 0; i < N; i++){\n",
        "    vector[i] = rand();\n",
        "    original[i] = vector[i];\n",
        "  }\n",
        "\n",
        "  int blockSize = 256;\n",
        "  int numBlocks = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "  scalar_multiplication<<<numBlocks, blockSize>>>(N, vector, scalar);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // --- Comprobación de errores ---\n",
        "  // Comprobar errores del kernel\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "    std::cerr << \"CUDA kernel error: \" << cudaGetErrorString(err) << \"\\n\";\n",
        "    return 1;\n",
        "  }\n",
        "\n",
        "  // Comprobar errores de la multiplicación\n",
        "  bool ok = true;\n",
        "  for (int i = 0; i < N; i++){\n",
        "    float expected = original[i] * scalar;\n",
        "    if (fabs(vector[i] - expected) > 1e-5f) {\n",
        "      std::cout << \"Error en índice \" << i\n",
        "                << \": obtenido = \" << vector[i]\n",
        "                << \", esperado = \" << expected << \"\\n\";\n",
        "      ok = false;\n",
        "      break;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (ok)\n",
        "    std::cout << \"Comprobación exitosa: todos los valores coinciden.\\n\";\n",
        "\n",
        "  cudaFree(vector);\n",
        "  cudaFree(original);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAW1TS70TmKm",
        "outputId": "fae0f696-7589-4e31-8d56-18ca43bb0081"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scavec_mult.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilación y resultados"
      ],
      "metadata": {
        "id": "gmvGMEH_knFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc -arch=compute_75 -code=sm_75 scavec_mult.cu -o scavec_mult_cu\n",
        "./scavec_mult_cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UWJaatTTs4B",
        "outputId": "973fb90e-172d-4879-b78b-29a1dc0485c9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comprobación exitosa: todos los valores coinciden.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de tiempo y entorno de ejecución"
      ],
      "metadata": {
        "id": "x33rWGqJkkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Información sobre el GPU asignado para la ejecución por Google Colab:"
      ],
      "metadata": {
        "id": "h_K4EnOkoDhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0p1AcBVYnt5",
        "outputId": "6b204e3b-5669-4713-a076-b6e2ffac3888"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  5 07:35:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiempo que toma el kernel para terminar la ejecución del programa:"
      ],
      "metadata": {
        "id": "FBkau_C_oMYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvprof ./scavec_mult_cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auAeDDn2cADM",
        "outputId": "dc0dd376-046e-480a-82f3-d46c293a0ce8"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==21755== NVPROF is profiling process 21755, command: ./scavec_mult_cu\n",
            "Comprobación exitosa: todos los valores coinciden.\n",
            "==21755== Profiling application: ./scavec_mult_cu\n",
            "==21755== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  1.7730ms         1  1.7730ms  1.7730ms  1.7730ms  scalar_multiplication(int, float*, float)\n",
            "      API calls:   98.76%  195.72ms         2  97.862ms  63.057us  195.66ms  cudaMallocManaged\n",
            "                    0.90%  1.7933ms         1  1.7933ms  1.7933ms  1.7933ms  cudaDeviceSynchronize\n",
            "                    0.20%  389.76us         2  194.88us  117.16us  272.60us  cudaFree\n",
            "                    0.07%  131.72us         1  131.72us  131.72us  131.72us  cudaLaunchKernel\n",
            "                    0.06%  124.83us       114  1.0940us     104ns  50.306us  cuDeviceGetAttribute\n",
            "                    0.01%  11.598us         1  11.598us  11.598us  11.598us  cuDeviceGetName\n",
            "                    0.00%  5.8270us         1  5.8270us  5.8270us  5.8270us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.4840us         3     494ns     160ns  1.1230us  cuDeviceGetCount\n",
            "                    0.00%     722ns         2     361ns     122ns     600ns  cuDeviceGet\n",
            "                    0.00%     651ns         1     651ns     651ns     651ns  cudaGetLastError\n",
            "                    0.00%     626ns         1     626ns     626ns     626ns  cuModuleGetLoadingMode\n",
            "                    0.00%     518ns         1     518ns     518ns     518ns  cuDeviceTotalMem\n",
            "                    0.00%     261ns         1     261ns     261ns     261ns  cuDeviceGetUuid\n",
            "\n",
            "==21755== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      54  75.852KB  4.0000KB  960.00KB  4.000000MB  469.9130us  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  356.2480us  Device To Host\n",
            "      11         -         -         -           -  1.720669ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referencias\n",
        "\n",
        "- Harris, M. (2025). An Even Easier Introduction to CUDA (Updated). *NVIDIA Technical Blog*. https://developer.nvidia.com/blog/even-easier-introduction-cuda/\n",
        "- NVIDIA. (2025). *2.1. Intro to CUDA C++ — CUDA Programming Guide. CUDA Programming Guide*. https://docs.nvidia.com/cuda/cuda-programming-guide/02-basics/intro-to-cuda-cpp.html"
      ],
      "metadata": {
        "id": "ftXq6CvrnWBA"
      }
    }
  ]
}
